{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "882b9d3b",
   "metadata": {},
   "source": [
    "# Generador de preguntas\n",
    "\n",
    "Debemos construir un dataset de preguntas para la evaluación de nuestro RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e6fc93ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_mistralai import ChatMistralAI\n",
    "from langchain_community.document_loaders import PyPDFDirectoryLoader\n",
    "\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import warnings\n",
    "from dotenv import load_dotenv\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f71e1729",
   "metadata": {},
   "source": [
    "Cargamos nuestra key de mistralai, necesaria para usar sus modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7face1b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "MISTRAL_API_KEY = os.getenv(\"MISTRAL_API_KEY\")\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dfef94f",
   "metadata": {},
   "source": [
    "Usaremos el modelo mistral-small, que es gratuito y funciona bastante bien"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d6c743fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatMistralAI(\n",
    "    model=\"mistral-small-latest\", \n",
    "    mistral_api_key=MISTRAL_API_KEY,\n",
    "    temperature=0.1, \n",
    "    random_seed=12345\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd42a920",
   "metadata": {},
   "source": [
    "Prompt que se encargará de generar el par pregunta-respuesta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4eca10d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "QA_generation_prompt = \"\"\"\n",
    "Tu tarea es generar una ÚNICA pregunta con su respectiva respuesta basándote únicamente en el contexto aportado.\n",
    "Tus preguntas deben estar relacionadas con la DANA (Depresión Aislada en Niveles Altos) ocurrida a finales de 2024.\n",
    "Las preguntas generadas deben tener un formato de preguntas frecuentas (FAQ).\n",
    "Debes formular tus preguntas imitando el estilo que usaría una persona afectada por la catástrofe buscando información.\n",
    "Tus preguntas deben poder ser respondidas usando una pieza específica del contexto.\n",
    "No debes mencionar cosas como \"de acuerdo a la información\" o \"según el contexto\".\n",
    "Escribe en ESPAÑOL.\n",
    "---\n",
    "Realiza tu respuestas como sigue, manteniendo un formato separado por comas (csv):\n",
    "\n",
    "\"tu pregunta\",\"tu respuesta\"\n",
    "\n",
    "---\n",
    "Contexto: {context}\\n\n",
    "Output:::\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc426570",
   "metadata": {},
   "source": [
    "Cargamos los documentos y generamos la chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0ba8447e",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = PyPDFDirectoryLoader(\"../my_data\").load()\n",
    "prompt = ChatPromptTemplate.from_template(QA_generation_prompt)\n",
    "chain =  prompt | llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37aba37b",
   "metadata": {},
   "source": [
    "Creamos el fichero y ejecutamos un bucle para obtener nuestro dataset completo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fa468e3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generando hoja de preguntas: 100%|██████████| 569/569 [1:09:40<00:00,  7.35s/páginas]\n"
     ]
    }
   ],
   "source": [
    "with open(\"preguntas_mistral_plus2.csv\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"Pregunta, Respuesta, Contexto, Recurso\\n\")\n",
    "    for doc in tqdm(documents, desc=\"Generando hoja de preguntas\", unit=\"páginas\"):\n",
    "        page_content = doc.page_content.replace('\\n', ' ').replace('\"', '\"\"')\n",
    "        response = chain.invoke({\"context\":page_content})\n",
    "        source = doc.metadata[\"source\"]\n",
    "        line = f'{response},\"{page_content}\",\"{source}\"' \n",
    "        f.write(line + \"\\n\")\n",
    "        time.sleep(2)   # to avoid rate limit issues"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
